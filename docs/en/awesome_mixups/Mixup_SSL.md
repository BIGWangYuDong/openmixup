# Awesome Mixup Methods for Self- and Semi-supervised Learning

 [![Awesome](https://awesome.re/badge.svg)](https://awesome.re) ![GitHub stars](https://img.shields.io/github/stars/Westlake-AI/openmixup?color=green) ![visitors](https://visitor-badge.glitch.me/badge?page_id=Westlake-AI/openmixup)

**We summarize mixup methods proposed for self- and semi-supervised visual representation learning.**
We are working on a survey of mixup methods. The list is on updating.

## Mixup Methods for Self-supervised Learning

1. **MixCo**, [[NIPSW'2020](https://arxiv.org/pdf/2010.06300.pdf)] [[code](https://github.com/Lee-Gihun/MixCo-Mixup-Contrast)]
   MixCo: Mix-up Contrastive Learning for Visual Representation.
2. **MoCHi**, [[NIPS'2020](https://arxiv.org/abs/2010.01028)] [[code](https://europe.naverlabs.com/mochi)]
   Hard Negative Mixing for Contrastive Learning.
3. **i-Mix**, [[ICLR'2021](https://openreview.net/pdf/c7fd4a731db5f1505f19ca2c4439421df41a8c7b.pdf)] [[code](https://github.com/kibok90/imix)]
   i-Mix A Domain-Agnostic Strategy for Contrastive Representation Learning.
4. **Un-Mix**, [[AAAI'2022](https://arxiv.org/pdf/2003.05438.pdf)] [[code](https://github.com/szq0214/Un-Mix)]
   Un-Mix: Rethinking Image Mixtures for Unsupervised Visual Representation.
5. **BSIM**, [[Arxiv'2020](https://arxiv.org/pdf/2011.13356.pdf)]
   Beyond Single Instance Multi-view Unsupervised Representation Learning.
6. **FT**, [[ICCV'2021](https://arxiv.org/abs/2108.02982)] [[code](https://github.com/DTennant/CL-Visualizing-Feature-Transformation)]
   Improving Contrastive Learning by Visualizing Feature Transformation.
7. **m-Mix**, [[Arxiv'2021](https://openreview.net/forum?id=lsljy2bG3n)]
   m-mix: Generating hard negatives via multiple samples mixing for contrastive learning.
8. **PCEA**, [[OpenReview'2021](https://openreview.net/forum?id=DnG8f7gweH4)]
   Piecing and Chipping: An effective solution for the information-erasing view generation in Self-supervised Learning.
9. **SAMix**, [[Arxiv'2021](https://arxiv.org/abs/2111.15454)] [[code](https://github.com/Westlake-AI/openmixup)]
   Boosting Discriminative Visual Representation Learning with Scenario-Agnostic Mixup.
10. **MixSiam**, [[OpenReview'2021](https://arxiv.org/abs/2111.02679)]
    MixSiam: A Mixture-based Approach to Self-supervised Representation Learning.
11. **MixSSL**, [[ICME'2021](https://arxiv.org/abs/2204.00901)]
    Mix-up Self-Supervised Learning for Contrast-agnostic Applications.
12. **CLIM**, [[BMVC'2021](https://arxiv.org/abs/2011.02697)]
    Center-wise Local Image Mixture For Contrastive Representation Learning.

## Mixup Methods for Semi-supervised Learning

1. **MixMatch**, [[NIPS'2019](https://arxiv.org/abs/1905.02249)] [[code](https://github.com/google-research/mixmatch)]
   MixMatch: A Holistic Approach to Semi-Supervised Learning.
2. **ReMixMatch**, [[ICLR'2020](https://openreview.net/forum?id=HklkeR4KPB)] [[code](https://github.com/google-research/remixmatch)]
   ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring.
3. **Core-Tuning**, [[NIPS'2021](https://arxiv.org/abs/2102.06605)] [[code](https://github.com/vanint/core-tuning)]
   Unleashing the Power of Contrastive Self-Supervised Visual Models via Contrast-Regularized Fine-Tuning.
4. **DFixMatch**, [[Arxiv'2022](https://arxiv.org/abs/2203.10761)] [[code](https://github.com/Westlake-AI/openmixup)]
   Decoupled Mixup for Data-efficient Learning.

## Contribution

Feel free to send [pull requests](https://github.com/Westlake-AI/openmixup/pulls) to add more links! Current contributors include: Siyuan Li ([@Lupin1998](https://github.com/Lupin1998)) and Zicheng Liu ([@pone7](https://github.com/pone7)).
